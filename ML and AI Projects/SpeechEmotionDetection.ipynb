{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"SpeechEmotionDetection.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyODyxMEN+LecrMQrxHXWarQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"nigvQPGmTllo","executionInfo":{"status":"ok","timestamp":1652190265014,"user_tz":420,"elapsed":8153,"user":{"displayName":"Arjun Chidambaran","userId":"15335744820933329132"}}},"outputs":[],"source":["import tensorflow as tf\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import os\n","import librosa\n","import librosa.display\n","import wave"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"metadata":{"id":"DrcbW8nHVygj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652190286632,"user_tz":420,"elapsed":20012,"user":{"displayName":"Arjun Chidambaran","userId":"15335744820933329132"}},"outputId":"6278183e-8cea-4225-a7d3-1b40adae41bb"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","source":["# !ls '/content/gdrive/MyDrive/Speech Recognition/speech-emotion-recognition-ravdess-data'\n","\n","file_counter = 0\n","i = 0\n","second_file = 0\n","\n","emotions_array = []\n","wav_array = []\n","\n","for file in os.listdir('/content/gdrive/MyDrive/Speech Recognition/speech-emotion-recognition-ravdess-data'):\n","    for actor_file in os.listdir('/content/gdrive/MyDrive/Speech Recognition/speech-emotion-recognition-ravdess-data/' + file + '/'):   \n","        # emotions array\n","\n","        # 01 = neutral, 02 = calm, 03 = happy, 04 = sad, 05 = angry, 06 = fearful, 07 = disgust, 08 = surprised\n","        wav_array.append(actor_file)\n","\n","        # wav_array = np.array(wav_array)\n","\n","        wav, sr = librosa.load('/content/gdrive/MyDrive/Speech Recognition/speech-emotion-recognition-ravdess-data/' + file + '/' + actor_file)\n","        # print(wav)\n","        # signal = wav.readframes(-1)\n","        # signal = np.fromstring(signal, \"int16\")\n","        # rate = wav.getframerate()\n","        # time = np.linspace(0, len(signal) / rate, num=len(signal))\n","\n","        # plt.figure(1)\n","        # plt.title(\"Signal Wave\")\n","        # plt.xlabel('Frames')\n","        # plt.ylabel('Amplitude')\n","        # plt.plot(wav)\n","        # plt.show()\n","\n","\n","        # plt.figure(2)\n","        # n_fft = 1024\n","        # D = np.abs(librosa.stft(wav[:n_fft], n_fft=n_fft, hop_length=n_fft+1))\n","        # plt.plot(D)\n","        # plt.title('Fournier Transform');\n","        # plt.xlabel('Frequency');\n","        # plt.ylabel('Amplitude');\n","\n","        # plt.figure(3)\n","        # S = librosa.feature.melspectrogram(wav, sr=sr, n_fft=n_fft, hop_length=512)\n","        # S_DB = librosa.power_to_db(S, ref=np.max)\n","        # librosa.display.specshow(S_DB, sr=sr, hop_length=512, x_axis='time', y_axis='mel');\n","        # plt.colorbar(format='%+2.0f dB');\n","\n","        # return emotions_array\n","\n","print(len(wav_array))\n","\n","for i in range(len(wav_array)):\n","  string = wav_array[i]\n","\n","  if(string[6:8] == '01'):\n","    emotion = 'neutral'\n","  elif(string[6:8] == '02'):\n","    emotion = 'calm'\n","  elif(string[6:8] == '03'):\n","    emotion = 'happy'\n","  elif(string[6:8] == '04'):\n","    emotion = 'sad'\n","  elif(string[6:8] == '05'):\n","    emotion = 'angry'\n","  elif(string[6:8] == '06'):\n","    emotion = 'fearful'\n","  elif(string[6:8] == '07'):\n","    emotion = 'disgust'\n","  else:\n","    emotion = 'surprised'\n","\n","  emotions_array.append(emotion)\n","\n","\n","\n","  print(emotions_array)\n","      \n","  # print(file_counter)\n","  # /content/gdrive/MyDrive/Speech Recognition/speech-emotion-recognition-ravdess-data/Actor_20/03-01-03-01-02-01-20.wav\n"],"metadata":{"id":"Krcl62liTQHu"},"execution_count":null,"outputs":[]}]}