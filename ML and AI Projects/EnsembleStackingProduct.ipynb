{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":230,"status":"ok","timestamp":1649775503777,"user":{"displayName":"Arjun Chidambaran","userId":"15335744820933329132"},"user_tz":420},"id":"ugXb6yOKkcSw"},"outputs":[],"source":["import zipfile\n","import pandas as pd \n","import numpy as np\n","from IPython.display import display\n","from pprint import pprint\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","import string\n","import re\n","from sklearn.model_selection import train_test_split\n","from sklearn.utils import resample"]},{"cell_type":"markdown","metadata":{"id":"lzjuai_8nyrs"},"source":["Tokenization Stage"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2882,"status":"ok","timestamp":1649775508065,"user":{"displayName":"Arjun Chidambaran","userId":"15335744820933329132"},"user_tz":420},"id":"5YOoJl7Dke6O","outputId":"d7eb3070-bdce-4c63-cf5b-e238e54d6d0a"},"outputs":[{"name":"stdout","output_type":"stream","text":["['empty' 'sadness' 'sadness' ... 'love' 'happiness' 'love']\n","['empty' 'sadness' 'enthusiasm' 'neutral' 'worry' 'surprise' 'love' 'fun'\n"," 'hate' 'happiness' 'boredom' 'relief' 'anger']\n","13\n","[[0. 1. 0. ... 0. 0. 0.]\n"," [0. 0. 1. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," ...\n"," [0. 1. 0. ... 0. 0. 0.]\n"," [0. 1. 0. ... 0. 0. 0.]\n"," [0. 1. 0. ... 0. 0. 0.]]\n","[[0. 1. 0. ... 0. 0. 0.]\n"," [0. 1. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," ...\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 1. ... 0. 0. 0.]]\n","12000\n","1000\n"]}],"source":["dataset = pd.read_csv('/content/Output/tweet_emotions.csv')\n","\n","content = dataset['content']\n","\n","contentArr = content.to_numpy()\n","\n","\n","contentArr_length = len(contentArr)\n","\n","sentiment = dataset['sentiment']\n","sentimentArr = sentiment.to_numpy()\n","\n","print(sentimentArr)\n","\n","sentimentArr_length = len(sentimentArr)\n","\n","sentimentUniqueArr = sentiment.unique()\n","print(sentimentUniqueArr)\n","\n","sentimentArr_unique_length = len(sentimentUniqueArr)\n","\n","print(sentimentArr_unique_length)\n","\n","tokenizer = Tokenizer(num_words=1000, oov_token='\u003coov\u003e')\n","sentimentTokenizer = Tokenizer(num_words=13)\n","\n","\n","def vocab_count(arr):\n","  vocab_size = 0\n","\n","  for sentences in arr:\n","    for j in sentences:\n","      vocab_size += 1\n","\n","  return vocab_size\n","\n","  print(vocab_count(contentArr))\n","\n","\n","def prepare_sentence(sentence):\n","  return re.sub(r'([{}])'.format(string.punctuation),r' ', sentence)\n","\n","def tokenization(arr):\n","  prepared_arr = []\n","  for sentence in arr:\n","    newSentence = prepare_sentence(sentence)\n","    prepared_arr.append(newSentence)\n","  \n","  tokenizer.fit_on_texts(prepared_arr)\n","  sequences = tokenizer.texts_to_sequences(prepared_arr)\n","  return pad_sequences(sequences)\n","\n","# Tried to_categorical\n","\n","def sentimentTokenization(arr):\n","  prepared_arr = []\n","  for sentence in arr:\n","    newSentence = prepare_sentence(sentence)\n","    prepared_arr.append(newSentence)\n","  \n","  sentimentTokenizer.fit_on_texts(prepared_arr)\n","  sequences = sentimentTokenizer.texts_to_sequences(prepared_arr)\n","  return pad_sequences(sequences)\n","\n","content_length = int(0.7 * len(contentArr))\n","sentiment_length = int(0.7 * len(sentimentArr))\n","\n","\n","contentNewArr = tokenization(contentArr)\n","sentimentInNumber = {}\n","sentimentNewArr = sentimentTokenization(sentimentArr)\n","# sentimentNewCArr = tf.keras.utils.to_categorical(sentimentNewArr)\n","\n","# unwanted_idx = []\n","\n","# for i, sentiment in enumerate(sentimentNewArr):\n","#   if(sentiment \u003e 13):\n","#     unwanted_idx.append(sentiment)\n","# print(len(unwanted_idx))\n","\n","training_sentences, testing_sentences, training_labels, testing_labels = train_test_split(contentNewArr, sentimentNewArr, test_size=0.3)\n","\n","training_labels = tf.keras.utils.to_categorical(training_labels)\n","testing_labels = tf.keras.utils.to_categorical(testing_labels)\n","\n","print(training_labels)\n","print(testing_labels)\n","\n","print(len(testing_labels))\n","\n","\n","# contentArr = content.to_numpy()\n","\n","vocab_size = tokenizer.num_words\n","print(vocab_size)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"83pTF3aAxmX3"},"source":["Models"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"RJRMG3ZAxl7E"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding (Embedding)       (None, None, 64)          64000     \n","                                                                 \n"," bidirectional (Bidirectiona  (None, 128)              66048     \n"," l)                                                              \n","                                                                 \n"," dropout (Dropout)           (None, 128)               0         \n","                                                                 \n"," dense (Dense)               (None, 64)                8256      \n","                                                                 \n"," dropout_1 (Dropout)         (None, 64)                0         \n","                                                                 \n"," dense_1 (Dense)             (None, 13)                845       \n","                                                                 \n","=================================================================\n","Total params: 139,149\n","Trainable params: 139,149\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/20\n","219/219 [==============================] - 22s 89ms/step - loss: 2.3021 - accuracy: 0.2186 - val_loss: 2.1410 - val_accuracy: 0.2658\n","Epoch 2/20\n","219/219 [==============================] - 19s 87ms/step - loss: 2.1225 - accuracy: 0.2682 - val_loss: 2.0166 - val_accuracy: 0.3183\n","Epoch 3/20\n","219/219 [==============================] - 19s 87ms/step - loss: 2.0209 - accuracy: 0.3146 - val_loss: 1.9659 - val_accuracy: 0.3354\n","Epoch 4/20\n","219/219 [==============================] - 19s 88ms/step - loss: 1.9852 - accuracy: 0.3261 - val_loss: 1.9452 - val_accuracy: 0.3416\n","Epoch 5/20\n","219/219 [==============================] - 19s 89ms/step - loss: 1.9664 - accuracy: 0.3315 - val_loss: 1.9515 - val_accuracy: 0.3380\n","Epoch 6/20\n","219/219 [==============================] - 19s 89ms/step - loss: 1.9563 - accuracy: 0.3354 - val_loss: 1.9354 - val_accuracy: 0.3434\n","Epoch 7/20\n","219/219 [==============================] - 20s 90ms/step - loss: 1.9398 - accuracy: 0.3414 - val_loss: 1.9270 - val_accuracy: 0.3466\n","Epoch 8/20\n","219/219 [==============================] - 19s 88ms/step - loss: 1.9318 - accuracy: 0.3475 - val_loss: 1.9291 - val_accuracy: 0.3434\n","Epoch 9/20\n","219/219 [==============================] - 19s 87ms/step - loss: 1.9271 - accuracy: 0.3499 - val_loss: 1.9203 - val_accuracy: 0.3457\n","Epoch 10/20\n","219/219 [==============================] - 19s 87ms/step - loss: 1.9176 - accuracy: 0.3507 - val_loss: 1.9183 - val_accuracy: 0.3459\n","Epoch 11/20\n","219/219 [==============================] - 19s 87ms/step - loss: 1.9105 - accuracy: 0.3541 - val_loss: 1.9127 - val_accuracy: 0.3485\n","Epoch 12/20\n","219/219 [==============================] - 19s 88ms/step - loss: 1.9079 - accuracy: 0.3546 - val_loss: 1.9185 - val_accuracy: 0.3473\n","Epoch 13/20\n","219/219 [==============================] - 19s 89ms/step - loss: 1.8993 - accuracy: 0.3569 - val_loss: 1.9122 - val_accuracy: 0.3500\n","Epoch 14/20\n","219/219 [==============================] - 19s 89ms/step - loss: 1.8955 - accuracy: 0.3586 - val_loss: 1.9102 - val_accuracy: 0.3523\n","Epoch 15/20\n","219/219 [==============================] - 19s 88ms/step - loss: 1.8896 - accuracy: 0.3615 - val_loss: 1.9121 - val_accuracy: 0.3511\n","Epoch 16/20\n","219/219 [==============================] - 19s 88ms/step - loss: 1.8827 - accuracy: 0.3636 - val_loss: 1.9167 - val_accuracy: 0.3499\n","Epoch 17/20\n","219/219 [==============================] - 24s 108ms/step - loss: 1.8797 - accuracy: 0.3676 - val_loss: 1.9115 - val_accuracy: 0.3507\n","Epoch 18/20\n","219/219 [==============================] - 19s 88ms/step - loss: 1.8759 - accuracy: 0.3683 - val_loss: 1.9181 - val_accuracy: 0.3489\n","Epoch 19/20\n","219/219 [==============================] - 19s 88ms/step - loss: 1.8702 - accuracy: 0.3692 - val_loss: 1.9158 - val_accuracy: 0.3507\n","Epoch 20/20\n","219/219 [==============================] - 19s 88ms/step - loss: 1.8665 - accuracy: 0.3693 - val_loss: 1.9299 - val_accuracy: 0.3498\n","Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_1 (Embedding)     (None, None, 64)          64000     \n","                                                                 \n"," lstm_1 (LSTM)               (None, 64)                33024     \n","                                                                 \n"," dropout_2 (Dropout)         (None, 64)                0         \n","                                                                 \n"," dense_2 (Dense)             (None, 64)                4160      \n","                                                                 \n"," dropout_3 (Dropout)         (None, 64)                0         \n","                                                                 \n"," dense_3 (Dense)             (None, 13)                845       \n","                                                                 \n","=================================================================\n","Total params: 102,029\n","Trainable params: 102,029\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/20\n","219/219 [==============================] - 13s 53ms/step - loss: 2.2452 - accuracy: 0.2123 - val_loss: 2.1415 - val_accuracy: 0.2620\n","Epoch 2/20\n","219/219 [==============================] - 11s 52ms/step - loss: 2.0903 - accuracy: 0.2802 - val_loss: 1.9720 - val_accuracy: 0.3305\n","Epoch 3/20\n","219/219 [==============================] - 11s 51ms/step - loss: 1.9873 - accuracy: 0.3211 - val_loss: 1.9425 - val_accuracy: 0.3391\n","Epoch 4/20\n","219/219 [==============================] - 11s 50ms/step - loss: 1.9519 - accuracy: 0.3303 - val_loss: 1.9304 - val_accuracy: 0.3422\n","Epoch 5/20\n","219/219 [==============================] - 11s 51ms/step - loss: 1.9236 - accuracy: 0.3439 - val_loss: 1.9093 - val_accuracy: 0.3540\n","Epoch 6/20\n","219/219 [==============================] - 11s 51ms/step - loss: 1.9075 - accuracy: 0.3526 - val_loss: 1.9023 - val_accuracy: 0.3567\n","Epoch 7/20\n","219/219 [==============================] - 11s 51ms/step - loss: 1.8928 - accuracy: 0.3590 - val_loss: 1.8993 - val_accuracy: 0.3602\n","Epoch 8/20\n","219/219 [==============================] - 11s 51ms/step - loss: 1.8757 - accuracy: 0.3640 - val_loss: 1.9045 - val_accuracy: 0.3568\n","Epoch 9/20\n","219/219 [==============================] - 11s 50ms/step - loss: 1.8670 - accuracy: 0.3664 - val_loss: 1.8976 - val_accuracy: 0.3559\n","Epoch 10/20\n","219/219 [==============================] - 11s 51ms/step - loss: 1.8550 - accuracy: 0.3730 - val_loss: 1.8985 - val_accuracy: 0.3598\n","Epoch 11/20\n","219/219 [==============================] - 11s 51ms/step - loss: 1.8457 - accuracy: 0.3744 - val_loss: 1.9075 - val_accuracy: 0.3561\n","Epoch 12/20\n","219/219 [==============================] - 11s 51ms/step - loss: 1.8330 - accuracy: 0.3795 - val_loss: 1.9057 - val_accuracy: 0.3577\n","Epoch 13/20\n","219/219 [==============================] - 11s 51ms/step - loss: 1.8238 - accuracy: 0.3815 - val_loss: 1.9097 - val_accuracy: 0.3604\n","Epoch 14/20\n","219/219 [==============================] - 11s 51ms/step - loss: 1.8143 - accuracy: 0.3858 - val_loss: 1.9174 - val_accuracy: 0.3575\n","Epoch 15/20\n","219/219 [==============================] - 11s 51ms/step - loss: 1.8076 - accuracy: 0.3912 - val_loss: 1.9212 - val_accuracy: 0.3536\n","Epoch 16/20\n","219/219 [==============================] - 11s 51ms/step - loss: 1.7948 - accuracy: 0.3911 - val_loss: 1.9224 - val_accuracy: 0.3528\n","Epoch 17/20\n","219/219 [==============================] - 11s 51ms/step - loss: 1.7866 - accuracy: 0.3947 - val_loss: 1.9198 - val_accuracy: 0.3536\n","Epoch 18/20\n","219/219 [==============================] - 12s 53ms/step - loss: 1.7762 - accuracy: 0.3990 - val_loss: 1.9348 - val_accuracy: 0.3517\n","Epoch 19/20\n","219/219 [==============================] - 12s 53ms/step - loss: 1.7659 - accuracy: 0.4028 - val_loss: 1.9486 - val_accuracy: 0.3528\n","Epoch 20/20\n","219/219 [==============================] - 12s 53ms/step - loss: 1.7581 - accuracy: 0.4037 - val_loss: 1.9470 - val_accuracy: 0.3511\n","Model: \"sequential_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_2 (Embedding)     (None, None, 64)          64000     \n","                                                                 \n"," bidirectional_1 (Bidirectio  (None, None, 128)        49920     \n"," nal)                                                            \n","                                                                 \n"," dropout_4 (Dropout)         (None, None, 128)         0         \n","                                                                 \n"," bidirectional_2 (Bidirectio  (None, 128)              74496     \n"," nal)                                                            \n","                                                                 \n"," dropout_5 (Dropout)         (None, 128)               0         \n","                                                                 \n"," dense_4 (Dense)             (None, 64)                8256      \n","                                                                 \n"," dropout_6 (Dropout)         (None, 64)                0         \n","                                                                 \n"," dense_5 (Dense)             (None, 13)                845       \n","                                                                 \n","=================================================================\n","Total params: 197,517\n","Trainable params: 197,517\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/20\n","219/219 [==============================] - 72s 289ms/step - loss: 2.2781 - accuracy: 0.2336 - val_loss: 2.0537 - val_accuracy: 0.3105\n","Epoch 2/20\n","219/219 [==============================] - 63s 286ms/step - loss: 2.0553 - accuracy: 0.3166 - val_loss: 1.9796 - val_accuracy: 0.3358\n","Epoch 3/20\n","219/219 [==============================] - 61s 280ms/step - loss: 1.9914 - accuracy: 0.3377 - val_loss: 1.9552 - val_accuracy: 0.3433\n","Epoch 4/20\n","219/219 [==============================] - 61s 279ms/step - loss: 1.9562 - accuracy: 0.3443 - val_loss: 1.9287 - val_accuracy: 0.3508\n","Epoch 5/20\n","219/219 [==============================] - 61s 278ms/step - loss: 1.9300 - accuracy: 0.3510 - val_loss: 1.9291 - val_accuracy: 0.3488\n","Epoch 6/20\n","219/219 [==============================] - 61s 277ms/step - loss: 1.9106 - accuracy: 0.3568 - val_loss: 1.9198 - val_accuracy: 0.3495\n","Epoch 7/20\n","219/219 [==============================] - 61s 277ms/step - loss: 1.8967 - accuracy: 0.3632 - val_loss: 1.9251 - val_accuracy: 0.3521\n","Epoch 8/20\n","219/219 [==============================] - 61s 277ms/step - loss: 1.8882 - accuracy: 0.3647 - val_loss: 1.9134 - val_accuracy: 0.3567\n","Epoch 9/20\n","219/219 [==============================] - 61s 278ms/step - loss: 1.8763 - accuracy: 0.3701 - val_loss: 1.9169 - val_accuracy: 0.3508\n","Epoch 10/20\n","219/219 [==============================] - 61s 277ms/step - loss: 1.8684 - accuracy: 0.3722 - val_loss: 1.9257 - val_accuracy: 0.3502\n","Epoch 11/20\n","219/219 [==============================] - 61s 277ms/step - loss: 1.8634 - accuracy: 0.3752 - val_loss: 1.9182 - val_accuracy: 0.3484\n","Epoch 12/20\n","219/219 [==============================] - 61s 277ms/step - loss: 1.8580 - accuracy: 0.3762 - val_loss: 1.9187 - val_accuracy: 0.3517\n","Epoch 13/20\n","219/219 [==============================] - 61s 277ms/step - loss: 1.8513 - accuracy: 0.3789 - val_loss: 1.9214 - val_accuracy: 0.3522\n","Epoch 14/20\n","219/219 [==============================] - 61s 278ms/step - loss: 1.8474 - accuracy: 0.3815 - val_loss: 1.9288 - val_accuracy: 0.3490\n","Epoch 15/20\n","219/219 [==============================] - 61s 280ms/step - loss: 1.8426 - accuracy: 0.3837 - val_loss: 1.9307 - val_accuracy: 0.3442\n","Epoch 16/20\n","219/219 [==============================] - 61s 281ms/step - loss: 1.8370 - accuracy: 0.3841 - val_loss: 1.9359 - val_accuracy: 0.3447\n","Epoch 17/20\n","219/219 [==============================] - 61s 280ms/step - loss: 1.8325 - accuracy: 0.3823 - val_loss: 1.9311 - val_accuracy: 0.3448\n","Epoch 18/20\n","219/219 [==============================] - 61s 279ms/step - loss: 1.8280 - accuracy: 0.3836 - val_loss: 1.9458 - val_accuracy: 0.3419\n","Epoch 19/20\n","219/219 [==============================] - 61s 279ms/step - loss: 1.8259 - accuracy: 0.3884 - val_loss: 1.9410 - val_accuracy: 0.3441\n","Epoch 20/20\n","219/219 [==============================] - 61s 280ms/step - loss: 1.8222 - accuracy: 0.3890 - val_loss: 1.9520 - val_accuracy: 0.3439\n"]}],"source":["embedding_dim = 64\n","\n","model1 = tf.keras.Sequential()\n","model1.add(tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim))\n","model1.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001))))\n","model1.add(tf.keras.layers.Dropout(0.3))\n","model1.add(tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n","model1.add(tf.keras.layers.Dropout(0.3))\n","model1.add(tf.keras.layers.Dense(13, activation='softmax'))\n","\n","model1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","model1.summary()\n","\n","history1 = model1.fit(training_sentences, training_labels, batch_size=128, validation_data=(testing_sentences, testing_labels), epochs=20)\n","\n","model1.save('m1.h5')  \n","model1.load_weights('m1.h5')\n","\n","\n","model2 = tf.keras.Sequential()\n","model2.add(tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim))\n","model2.add(tf.keras.layers.LSTM(64, activation='relu'))\n","model2.add(tf.keras.layers.Dropout(0.3))\n","model2.add(tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n","model2.add(tf.keras.layers.Dropout(0.3))\n","model2.add(tf.keras.layers.Dense(13, activation='softmax'))\n","model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","model2.summary()\n","\n","history2 = model2.fit(training_sentences, training_labels, batch_size=128, validation_data=(testing_sentences, testing_labels), epochs=20)\n","\n","model2.save('m2.h5')  \n","model2.load_weights('m2.h5')\n","\n","\n","model3 = tf.keras.Sequential()\n","model3.add(tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim))\n","model3.add(tf.keras.layers.Bidirectional(tf.keras.layers.GRU(64, return_sequences=True, recurrent_dropout = 0.4, kernel_regularizer=tf.keras.regularizers.l1_l2(l1=1e-5, l2=1e-4), activity_regularizer=tf.keras.regularizers.l2(1e-5))))\n","model3.add(tf.keras.layers.Dropout(0.3))\n","model3.add(tf.keras.layers.Bidirectional(tf.keras.layers.GRU(64, recurrent_dropout = 0.4, kernel_regularizer=tf.keras.regularizers.l1_l2(l1=1e-5, l2=1e-4), activity_regularizer=tf.keras.regularizers.l2(1e-5))))\n","model3.add(tf.keras.layers.Dropout(0.3))\n","model3.add(tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n","model3.add(tf.keras.layers.Dropout(0.3))\n","model3.add(tf.keras.layers.Dense(13, activation='softmax'))\n","\n","model3.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","model3.summary()\n","\n","history3 = model3.fit(training_sentences, training_labels, batch_size=128, validation_data=(testing_sentences, testing_labels), epochs=20)\n","\n","model3.save('m3.h5')  \n","model3.load_weights('m3.h5')\n"]},{"cell_type":"markdown","metadata":{"id":"bRrB3HIh18_Y"},"source":["Loading all Models\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":374},"executionInfo":{"elapsed":17460,"status":"error","timestamp":1649743261459,"user":{"displayName":"Arjun Chidambaran","userId":"15335744820933329132"},"user_tz":420},"id":"WG-_-KWy18O_","outputId":"40c21b38-fe70-4ce6-e851-1741942a4ed2"},"outputs":[{"name":"stdout","output_type":"stream","text":["0\n"]},{"ename":"IndexError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-8-e3f029538716\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mstacked_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 38\u001b[0;31m \u001b[0mstacked_prediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstacked_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesting_sentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfit_stacked_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmembers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m\u003cipython-input-8-e3f029538716\u003e\u001b[0m in \u001b[0;36mstacked_predictions\u001b[0;34m(members, x_input)\u001b[0m\n\u001b[1;32m     32\u001b[0m       \u001b[0mstacked_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstacked_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 34\u001b[0;31m   \u001b[0mstacked_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstacked_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstacked_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacked_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mstacked_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mstacked_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: tuple index out of range"]}],"source":["from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score\n","\n","num_models = 3\n","\n","def get_all_models(num_models):\n","  all_models = list()\n","  for i in range(num_models):\n","    modelFile = '/content/' + 'm' + str(i+1) + '.h5'\n","    model = keras.models.load_model(modelFile)\n","    all_models.append(model)\n","  \n","  return all_models\n","\n","\n","models = get_all_models(num_models)\n","\n","\n","def stacked_predictions(members, x_input):\n","  stacked_list = list()\n","  stacked_arr = np.array(stacked_list)\n","\n","  print(len(stacked_arr))\n","\n","  for model in members:\n","    stacked_arr = None\n","    model_pred = model.predict(x_input)\n","\n","    if(stacked_arr is None):\n","      stacked_arr = model_pred\n","    else:\n","      stacked_arr = np.concatenate((stacked_arr, model_pred), axis=0)\n","\n","  stacked_arr = stacked_arr.reshape((stacked_arr.shape[0], stacked_arr.shape[1] * stacked_arr.shape[2]))\n","\n","  return stacked_arr\n","\n","stacked_prediction = stacked_predictions(models, testing_sentences)\n","\n","def fit_stacked_model(members, x_test, y_test):\n","  model = LogisticRegression()\n","  model.fit(stacked_prediction, y_test)\n","\n","  return model\n","\n","final_model = fit_stacked_model(models, testing_sentences, testing_labels)\n","\n","def final_predictions(members, x_test, y_test):\n","  final_predictions = final_model.predict(stacked_prediction)\n","  return final_predictions\n","\n","y_test_predictions = final_predictions(models, testing_sentences, testing_labels)\n","\n","print(y_test_predictions)\n","model_accuracy_score = accuracy_score(testing_labels, y_test_predictions)\n","\n","print(model_accuracy_score)\n","\n","\n","\n","\n","  \n","\n","\n","\n","\n","    "]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMmPNgKVXRycjEECLz1hQiH","collapsed_sections":[],"name":"EnsembleStackingProduct.ipynb","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}